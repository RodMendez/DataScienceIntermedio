{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d2c505",
   "metadata": {},
   "source": [
    "# Procesamiento de lenguaje natural (NLP)\n",
    "\n",
    "![](https://raw.githubusercontent.com/igomezv/DataScienceIntermedio/main/img/NLP_pipeline.jpeg)\n",
    "Fuente de la imagen: Turing.com\n",
    "\n",
    "## 1. Segmentación de enunciados\n",
    "\n",
    "![](https://s3.amazonaws.com/work-sample-images/blog_segmentation.jpg)\n",
    "Fuente de la imagen: tm-town.com\n",
    "\n",
    "## 2.  Tokenization\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*UhfwmhMN9sdfcWIbO5_tGg.jpeg)\n",
    "Fuente de la imagen: Medium.com\n",
    "\n",
    "## 3. Stemming y  4. Lemmatization\n",
    "\n",
    "![](https://miro.medium.com/max/640/1*HLQgkMt5-g5WO5VpNuTl_g.jpeg)\n",
    "Fuente de la imagen: medium.com\n",
    "\n",
    "![](https://raw.githubusercontent.com/igomezv/DataScienceIntermedio/main/img/stemmingvslemma.png)\n",
    "Fuente de la imagen: businessprocessincubator.com\n",
    "\n",
    "\n",
    "## 5. Stop words\n",
    "![](https://user.oc-static.com/upload/2021/01/06/16099626487943_P1C2.png)\n",
    "Fuente de la imagen: openclassrooms.com\n",
    "\n",
    "## 6. Dependency parsing\n",
    "\n",
    "(Análisis de dependencia). Se utiliza principalmente para averiguar cómo se relacionan entre sí todas las palabras de una oración. Para encontrar la dependencia, podemos construir un árbol y asignar una sola palabra como palabra principal. El verbo principal de la oración actuará como el nodo raíz.\n",
    "![](https://files.realpython.com/media/displacy_dependency_parse.de72f9b1d115.png)\n",
    "Fuente: RealPython.\n",
    "\n",
    "\n",
    "## 7. Part of speech tagging\n",
    "\n",
    "(Etiquetado de parte del discurso).\n",
    "\n",
    "![](https://miro.medium.com/max/640/1*004yTJkoLe7g8KC8V7-ULw.png)\n",
    "Fuente de la imagen: medium.com\n",
    "\n",
    "![](https://www.researchgate.net/profile/Cigdem-Aytekin-3/publication/337773927/figure/fig1/AS:832915193733120@1575593865084/Natural-Language-Processing-Topics-Adali-2013-4.png)\n",
    "Fuente de la imagen: Sutcu, Cem Sefa & Aytekin, Cigdem. (2019)\n",
    "\n",
    "![](https://files.realpython.com/media/NLP-for-Beginners-Pythons-Natural-Language-Toolkit-NLTK_Watermarked.16a787c1e9c6.jpg)\n",
    "Fuente de la imagen: realpython.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59458a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/isidro/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b51b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e2d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', ',', 'just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0fbb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d4c38",
   "metadata": {},
   "source": [
    "Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cfa21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
