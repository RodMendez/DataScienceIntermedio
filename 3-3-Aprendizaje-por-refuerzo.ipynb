{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por refuerzo (posponer al viernes)\n",
    "\n",
    "Instalar las siguientes librerias para usar esta notebook:\n",
    "\n",
    "!pip install cmake pygame gym[all] pip stable_baselines3\n",
    "\n",
    "Referencia: https://www.gocoder.one/blog/rl-tutorial-with-openai-gym\n",
    "\n",
    "![](https://raw.githubusercontent.com/igomezv/DataScienceIntermedio/main/img/refuerzo.png)\n",
    "Fuente de la imagen: medium.com\n",
    "\n",
    "![](https://raw.githubusercontent.com/igomezv/DataScienceIntermedio/main/img/RLdog.jpg)\n",
    "Fuente: kdnuggets.com\n",
    "\n",
    "Objetivo: maximizar la recompenza.\n",
    "\n",
    "**Definiciones importantes:**\n",
    "\n",
    "- Agente: modelo a entrenar para que tome decisiones.\n",
    "- Ambiente: Entorno donde interactúa el agente. El ambiente limita y pone reglas. \n",
    "\n",
    "Entre ambiente y agente hay las siguientes relaciones: \n",
    "\n",
    "- Acción: posibles acciones que puede tomar el agente en determinado momento.\n",
    "- Estado (del ambiente): indicadores del ambiente sobre cómo están los diversos elementos que lo componen en determinado momento.\n",
    "- Recompensas (o penalización): cada acción del agente obtiene un premio o una penalización. \n",
    "\n",
    "Ver: https://towardsdatascience.com/hands-on-introduction-to-reinforcement-learning-in-python-da07f7aaca88 \n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/igomezv/DataScienceIntermedio/main/img/RLalg.png)\n",
    "Fuente: medium.com\n",
    "\n",
    "#### Usar el entorno TAXI\n",
    "\n",
    "**Contexto:** Taxi es un entorno disponible en Open-IA gym (https://www.gymlibrary.dev/environments/toy_text/taxi/).\n",
    "\n",
    "- El objetivo de Taxi es recoger pasajeros y dejarlos en el destino en la menor cantidad de movimientos. \n",
    "\n",
    "- Se comparara un agente de taxis que realiza acciones al azar con uno entrenado mediante Aprendizaje Reforzado.\n",
    "\n",
    "- Acciones: moverse hacia arriba, abajo, izquierda, derecha, recoger o dejar pasajeros.\n",
    "\n",
    "Descripción de la documentación:\n",
    "\n",
    "Hay cuatro ubicaciones designadas en el mundo de la cuadrícula indicadas por R (rojo), G (verde), Y (amarillo) y B (azul). Cuando el episodio inicia, el taxi parte de una casilla aleatoria y el pasajero se encuentra en una ubicación aleatoria. El taxi conduce hasta la ubicación del pasajero, lo recoge, conduce hasta el destino del pasajero (otra de las cuatro ubicaciones especificadas) y luego deja al pasajero. Una vez que se deja al pasajero, el episodio termina.\n",
    "\n",
    "Map:\n",
    "\n",
    "+---------+\n",
    "\n",
    "|R: | : :G|\n",
    "\n",
    "| : | : : |\n",
    "\n",
    "| : : : : |\n",
    "\n",
    "| | : | : |\n",
    "\n",
    "|Y| : |B: |\n",
    "\n",
    "+---------+\n",
    "\n",
    "##### Comportamiento\n",
    "\n",
    "\n",
    "Hay 6 acciones deterministas discretas:\n",
    "\n",
    "    0: mover al sur\n",
    "\n",
    "    1: mover al norte\n",
    "\n",
    "    2: moverse hacia el este\n",
    "\n",
    "    3: muévete hacia el oeste\n",
    "\n",
    "    4: pasajero de recogida\n",
    "\n",
    "    5: dejar al pasajero\n",
    "\n",
    "Observaciones\n",
    "\n",
    "Hay 500 estados discretos ya que hay 25 posiciones de taxi, 5 ubicaciones posibles del pasajero (incluido el caso cuando el pasajero está en el taxi) y 4 ubicaciones de destino.\n",
    "\n",
    "Tenga en cuenta que hay 400 estados a los que se puede llegar durante un episodio. Los estados faltantes corresponden a situaciones en las que el pasajero se encuentra en el mismo lugar que su destino, ya que esto suele indicar el final de un episodio. Se pueden observar cuatro estados adicionales justo después de un episodio exitoso, cuando tanto el pasajero como el taxi están en el destino. Esto da un total de 404 estados discretos alcanzables.\n",
    "\n",
    "Cada espacio de estado está representado por la tupla: (fila_taxi, col_taxi, ubicación_pasajero, destino)\n",
    "\n",
    "\n",
    "Ubicaciones de pasajeros:\n",
    "\n",
    "    0: R (rojo)\n",
    "\n",
    "    1: G (verde)\n",
    "\n",
    "    2: Y (amarillo)\n",
    "\n",
    "    3: B (azul)\n",
    "\n",
    "    4: en taxi\n",
    "\n",
    "Destinos:\n",
    "\n",
    "    0: R (rojo)\n",
    "\n",
    "    1: G (verde)\n",
    "\n",
    "    2: Y (amarillo)\n",
    "\n",
    "    3: B (azul)\n",
    "\n",
    "Recompensas\n",
    "\n",
    "     -1 por paso a menos que se active otra recompensa.\n",
    "\n",
    "     +20 entregando pasajero.\n",
    "\n",
    "     -10 ejecutar acciones de “recogida” y “devolución” de forma ilegal.\n",
    "     \n",
    "     - Una ilegalidad consiste en ejecutar las acciones\"recoger\"o \"devolver\" en lugares donde no hay personas.\n",
    "\n",
    "![](https://www.gocoder.one/static/state-rewards-62ab43a53e07062b531b3199a8bab5b3.png)\n",
    "\n",
    "Como llegar al punto R sin perder tantos puntos?\n",
    "\n",
    "## Q-Learning\n",
    "\n",
    "### Tablas-Q\n",
    "\n",
    "Una tabla Q es una tabla de búsqueda que almacena valores que representan las recompensas futuras máximas esperadas que el agente puede esperar por una acción determinada en un estado determinado (conocidos como valores Q).\n",
    "\n",
    "![](https://i.stack.imgur.com/Bn6MY.gif)\n",
    "\n",
    "Estas tablas se suelen inicializar en 0s\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "\n",
    "\n",
    "Hyperparámetros:\n",
    "\n",
    "- Tasa de aprendizaje (α): qué tanto el agente debe aceptar nueva información sobre la información previamente aprendida\n",
    "\n",
    "- Factor de descuento (γ): qué tanto el agente debe considerar las recompensas que podría recibir en el futuro frente a su recompensa inmediata.\n",
    "\n",
    "#### Primero, analicemos el comportamiento aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new instance of taxi, and get the initial state\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def randomtaxi():\n",
    "    total_reward = 0 \n",
    "    # crear entorno de Taxi\n",
    "    env = gym.make('Taxi-v3')\n",
    "\n",
    "    # crear una instancia de Taxi, y obtener un estado inicial\n",
    "    state = env.reset()\n",
    "\n",
    "    num_steps = 99\n",
    "\n",
    "    for s in range(num_steps+1):\n",
    "        print(\"Paso: {}/{}\".format(s+1, num_steps+1))\n",
    "\n",
    "        # muestrear una accion aleatoria de la lista de acciones posibles\n",
    "        action = env.action_space.sample()\n",
    "        # ejecutar esta accion sobre el entorno\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # Update to our new state\n",
    "        state = new_state\n",
    "        total_reward += reward \n",
    "        print(\"Accion {} Estado {} Recompensa {} Total rec {}\".format(action, state, reward, total_reward))\n",
    "\n",
    "\n",
    "        # imprimir nuevo estado\n",
    "        env.render()  \n",
    "\n",
    "        # if done, finish episode\n",
    "        if done == True:\n",
    "            break        \n",
    "            \n",
    "            \n",
    "    # terminar y cerrar el entorno del taxi\n",
    "    env.close()\n",
    "    return total_reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso: 1/100\n",
      "Accion 1 Estado 369 Recompensa -1 Total rec -1\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 2/100\n",
      "Accion 3 Estado 369 Recompensa -1 Total rec -2\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 3/100\n",
      "Accion 2 Estado 389 Recompensa -1 Total rec -3\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 4/100\n",
      "Accion 4 Estado 389 Recompensa -10 Total rec -13\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 5/100\n",
      "Accion 3 Estado 369 Recompensa -1 Total rec -14\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 6/100\n",
      "Accion 2 Estado 389 Recompensa -1 Total rec -15\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 7/100\n",
      "Accion 2 Estado 389 Recompensa -1 Total rec -16\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 8/100\n",
      "Accion 4 Estado 389 Recompensa -10 Total rec -26\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 9/100\n",
      "Accion 4 Estado 389 Recompensa -10 Total rec -36\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 10/100\n",
      "Accion 1 Estado 289 Recompensa -1 Total rec -37\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 11/100\n",
      "Accion 4 Estado 289 Recompensa -10 Total rec -47\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 12/100\n",
      "Accion 3 Estado 269 Recompensa -1 Total rec -48\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 13/100\n",
      "Accion 5 Estado 269 Recompensa -10 Total rec -58\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 14/100\n",
      "Accion 4 Estado 269 Recompensa -10 Total rec -68\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 15/100\n",
      "Accion 3 Estado 249 Recompensa -1 Total rec -69\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 16/100\n",
      "Accion 0 Estado 349 Recompensa -1 Total rec -70\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 17/100\n",
      "Accion 2 Estado 349 Recompensa -1 Total rec -71\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 18/100\n",
      "Accion 4 Estado 349 Recompensa -10 Total rec -81\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 19/100\n",
      "Accion 3 Estado 329 Recompensa -1 Total rec -82\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 20/100\n",
      "Accion 3 Estado 329 Recompensa -1 Total rec -83\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 21/100\n",
      "Accion 1 Estado 229 Recompensa -1 Total rec -84\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 22/100\n",
      "Accion 3 Estado 209 Recompensa -1 Total rec -85\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 23/100\n",
      "Accion 1 Estado 109 Recompensa -1 Total rec -86\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 24/100\n",
      "Accion 1 Estado 9 Recompensa -1 Total rec -87\n",
      "+---------+\n",
      "|\u001b[43mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 25/100\n",
      "Accion 5 Estado 9 Recompensa -10 Total rec -97\n",
      "+---------+\n",
      "|\u001b[43mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 26/100\n",
      "Accion 0 Estado 109 Recompensa -1 Total rec -98\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 27/100\n",
      "Accion 4 Estado 109 Recompensa -10 Total rec -108\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 28/100\n",
      "Accion 3 Estado 109 Recompensa -1 Total rec -109\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 29/100\n",
      "Accion 4 Estado 109 Recompensa -10 Total rec -119\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 30/100\n",
      "Accion 4 Estado 109 Recompensa -10 Total rec -129\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 31/100\n",
      "Accion 2 Estado 129 Recompensa -1 Total rec -130\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 32/100\n",
      "Accion 0 Estado 229 Recompensa -1 Total rec -131\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 33/100\n",
      "Accion 5 Estado 229 Recompensa -10 Total rec -141\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 34/100\n",
      "Accion 5 Estado 229 Recompensa -10 Total rec -151\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 35/100\n",
      "Accion 5 Estado 229 Recompensa -10 Total rec -161\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 36/100\n",
      "Accion 5 Estado 229 Recompensa -10 Total rec -171\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 37/100\n",
      "Accion 3 Estado 209 Recompensa -1 Total rec -172\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 38/100\n",
      "Accion 0 Estado 309 Recompensa -1 Total rec -173\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 39/100\n",
      "Accion 2 Estado 309 Recompensa -1 Total rec -174\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 40/100\n",
      "Accion 3 Estado 309 Recompensa -1 Total rec -175\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 41/100\n",
      "Accion 4 Estado 309 Recompensa -10 Total rec -185\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 42/100\n",
      "Accion 0 Estado 409 Recompensa -1 Total rec -186\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 43/100\n",
      "Accion 4 Estado 417 Recompensa -1 Total rec -187\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 44/100\n",
      "Accion 3 Estado 417 Recompensa -1 Total rec -188\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 45/100\n",
      "Accion 2 Estado 417 Recompensa -1 Total rec -189\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 46/100\n",
      "Accion 2 Estado 417 Recompensa -1 Total rec -190\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 47/100\n",
      "Accion 5 Estado 409 Recompensa -1 Total rec -191\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 48/100\n",
      "Accion 4 Estado 417 Recompensa -1 Total rec -192\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 49/100\n",
      "Accion 0 Estado 417 Recompensa -1 Total rec -193\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 50/100\n",
      "Accion 4 Estado 417 Recompensa -10 Total rec -203\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 51/100\n",
      "Accion 2 Estado 417 Recompensa -1 Total rec -204\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 52/100\n",
      "Accion 5 Estado 409 Recompensa -1 Total rec -205\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 53/100\n",
      "Accion 5 Estado 409 Recompensa -10 Total rec -215\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 54/100\n",
      "Accion 4 Estado 417 Recompensa -1 Total rec -216\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 55/100\n",
      "Accion 0 Estado 417 Recompensa -1 Total rec -217\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 56/100\n",
      "Accion 1 Estado 317 Recompensa -1 Total rec -218\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 57/100\n",
      "Accion 2 Estado 317 Recompensa -1 Total rec -219\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 58/100\n",
      "Accion 5 Estado 317 Recompensa -10 Total rec -229\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 59/100\n",
      "Accion 5 Estado 317 Recompensa -10 Total rec -239\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 60/100\n",
      "Accion 5 Estado 317 Recompensa -10 Total rec -249\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 61/100\n",
      "Accion 2 Estado 317 Recompensa -1 Total rec -250\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 62/100\n",
      "Accion 1 Estado 217 Recompensa -1 Total rec -251\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 63/100\n",
      "Accion 1 Estado 117 Recompensa -1 Total rec -252\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 64/100\n",
      "Accion 2 Estado 137 Recompensa -1 Total rec -253\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 65/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -254\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 66/100\n",
      "Accion 5 Estado 117 Recompensa -10 Total rec -264\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 67/100\n",
      "Accion 4 Estado 117 Recompensa -10 Total rec -274\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 68/100\n",
      "Accion 2 Estado 137 Recompensa -1 Total rec -275\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 69/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -276\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 70/100\n",
      "Accion 5 Estado 117 Recompensa -10 Total rec -286\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 71/100\n",
      "Accion 4 Estado 117 Recompensa -10 Total rec -296\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 72/100\n",
      "Accion 0 Estado 217 Recompensa -1 Total rec -297\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 73/100\n",
      "Accion 5 Estado 217 Recompensa -10 Total rec -307\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 74/100\n",
      "Accion 1 Estado 117 Recompensa -1 Total rec -308\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 75/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -309\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 76/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -310\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 77/100\n",
      "Accion 4 Estado 117 Recompensa -10 Total rec -320\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 78/100\n",
      "Accion 2 Estado 137 Recompensa -1 Total rec -321\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 79/100\n",
      "Accion 2 Estado 137 Recompensa -1 Total rec -322\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 80/100\n",
      "Accion 4 Estado 137 Recompensa -10 Total rec -332\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 81/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -333\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 82/100\n",
      "Accion 1 Estado 17 Recompensa -1 Total rec -334\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 83/100\n",
      "Accion 1 Estado 17 Recompensa -1 Total rec -335\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 84/100\n",
      "Accion 3 Estado 17 Recompensa -1 Total rec -336\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 85/100\n",
      "Accion 0 Estado 117 Recompensa -1 Total rec -337\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 86/100\n",
      "Accion 4 Estado 117 Recompensa -10 Total rec -347\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Paso: 87/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -348\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 88/100\n",
      "Accion 2 Estado 137 Recompensa -1 Total rec -349\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Paso: 89/100\n",
      "Accion 5 Estado 137 Recompensa -10 Total rec -359\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 90/100\n",
      "Accion 5 Estado 137 Recompensa -10 Total rec -369\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 91/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -370\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 92/100\n",
      "Accion 3 Estado 117 Recompensa -1 Total rec -371\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 93/100\n",
      "Accion 0 Estado 217 Recompensa -1 Total rec -372\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Paso: 94/100\n",
      "Accion 5 Estado 217 Recompensa -10 Total rec -382\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 95/100\n",
      "Accion 5 Estado 217 Recompensa -10 Total rec -392\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 96/100\n",
      "Accion 5 Estado 217 Recompensa -10 Total rec -402\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Paso: 97/100\n",
      "Accion 1 Estado 117 Recompensa -1 Total rec -403\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 98/100\n",
      "Accion 1 Estado 17 Recompensa -1 Total rec -404\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Paso: 99/100\n",
      "Accion 3 Estado 17 Recompensa -1 Total rec -405\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Paso: 100/100\n",
      "Accion 0 Estado 117 Recompensa -1 Total rec -406\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-406"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomtaxi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "\n",
    "def rltaxi():\n",
    "\n",
    "    # create Taxi environment\n",
    "    env = gym.make('Taxi-v3')\n",
    "\n",
    "    # initialize q-table\n",
    "    state_size = env.observation_space.n\n",
    "    action_size = env.action_space.n\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "\n",
    "    # hyperparameters\n",
    "    learning_rate = 0.9\n",
    "    discount_rate = 0.8\n",
    "    epsilon = 1.0\n",
    "    decay_rate= 0.005\n",
    "\n",
    "    # training variables\n",
    "    num_episodes = 1000\n",
    "    max_steps = 99 # per episode\n",
    "\n",
    "    # training\n",
    "    for episode in range(num_episodes):\n",
    "\n",
    "        # reset the environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        for s in range(max_steps):\n",
    "\n",
    "            # exploration-exploitation tradeoff\n",
    "            if random.uniform(0,1) < epsilon:\n",
    "                # explore\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # exploit\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # take action and observe reward\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Q-learning algorithm\n",
    "            qtable[state,action] = qtable[state,action] + learning_rate * (reward + discount_rate * np.max(qtable[new_state,:])-qtable[state,action])\n",
    "\n",
    "            # Update to our new state\n",
    "            state = new_state\n",
    "\n",
    "            # if done, finish episode\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        # Decrease epsilon\n",
    "        epsilon = np.exp(-decay_rate*episode)\n",
    "\n",
    "    print(f\"Training completed over {num_episodes} episodes\")\n",
    "    input(\"Press Enter to watch trained agent...\")\n",
    "\n",
    "    # watch trained agent\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    for s in range(max_steps+1):\n",
    "\n",
    "        print(f\"TRAINED AGENT\")\n",
    "        print(\"Paso {}\".format(s+1))\n",
    "\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "        total_reward += reward \n",
    "        print(\"Accion {} Estado {} Recompensa {} Total rec {}\".format(action, state, reward, total_reward))\n",
    "        state = new_state\n",
    "#comentar esto y volver a correr\n",
    "       if done == True:\n",
    "           break\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed over 1000 episodes\n",
      "Press Enter to watch trained agent...\n",
      "TRAINED AGENT\n",
      "Paso 1\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 33 Recompensa -1 Total rec -2\n",
      "TRAINED AGENT\n",
      "Paso 2\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 133 Recompensa -1 Total rec -4\n",
      "TRAINED AGENT\n",
      "Paso 3\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Accion 2 Estado 233 Recompensa -1 Total rec -6\n",
      "TRAINED AGENT\n",
      "Paso 4\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Accion 2 Estado 253 Recompensa -1 Total rec -8\n",
      "TRAINED AGENT\n",
      "Paso 5\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 273 Recompensa -1 Total rec -10\n",
      "TRAINED AGENT\n",
      "Paso 6\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 373 Recompensa -1 Total rec -12\n",
      "TRAINED AGENT\n",
      "Paso 7\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[42mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Accion 4 Estado 473 Recompensa -1 Total rec -14\n",
      "TRAINED AGENT\n",
      "Paso 8\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[42m_\u001b[0m: |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Accion 1 Estado 477 Recompensa -1 Total rec -16\n",
      "TRAINED AGENT\n",
      "Paso 9\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[42m_\u001b[0m|\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Accion 2 Estado 377 Recompensa -1 Total rec -18\n",
      "TRAINED AGENT\n",
      "Paso 10\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : :\u001b[42m_\u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Accion 1 Estado 397 Recompensa -1 Total rec -20\n",
      "TRAINED AGENT\n",
      "Paso 11\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : :\u001b[42m_\u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Accion 1 Estado 297 Recompensa -1 Total rec -22\n",
      "TRAINED AGENT\n",
      "Paso 12\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Accion 1 Estado 197 Recompensa -1 Total rec -24\n",
      "TRAINED AGENT\n",
      "Paso 13\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Accion 5 Estado 97 Recompensa 20 Total rec 16\n",
      "TRAINED AGENT\n",
      "Paso 14\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 85 Recompensa -1 Total rec 14\n",
      "TRAINED AGENT\n",
      "Paso 15\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 185 Recompensa -1 Total rec 12\n",
      "TRAINED AGENT\n",
      "Paso 16\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 285 Recompensa -1 Total rec 10\n",
      "TRAINED AGENT\n",
      "Paso 17\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 385 Recompensa -1 Total rec 8\n",
      "TRAINED AGENT\n",
      "Paso 18\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec 6\n",
      "TRAINED AGENT\n",
      "Paso 19\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec 4\n",
      "TRAINED AGENT\n",
      "Paso 20\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec 2\n",
      "TRAINED AGENT\n",
      "Paso 21\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec 0\n",
      "TRAINED AGENT\n",
      "Paso 22\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -2\n",
      "TRAINED AGENT\n",
      "Paso 23\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -4\n",
      "TRAINED AGENT\n",
      "Paso 24\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -6\n",
      "TRAINED AGENT\n",
      "Paso 25\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -8\n",
      "TRAINED AGENT\n",
      "Paso 26\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -10\n",
      "TRAINED AGENT\n",
      "Paso 27\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -12\n",
      "TRAINED AGENT\n",
      "Paso 28\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -14\n",
      "TRAINED AGENT\n",
      "Paso 29\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -16\n",
      "TRAINED AGENT\n",
      "Paso 30\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -18\n",
      "TRAINED AGENT\n",
      "Paso 31\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -20\n",
      "TRAINED AGENT\n",
      "Paso 32\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -22\n",
      "TRAINED AGENT\n",
      "Paso 33\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -24\n",
      "TRAINED AGENT\n",
      "Paso 34\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -26\n",
      "TRAINED AGENT\n",
      "Paso 35\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -28\n",
      "TRAINED AGENT\n",
      "Paso 36\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -30\n",
      "TRAINED AGENT\n",
      "Paso 37\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -32\n",
      "TRAINED AGENT\n",
      "Paso 38\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -34\n",
      "TRAINED AGENT\n",
      "Paso 39\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -36\n",
      "TRAINED AGENT\n",
      "Paso 40\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -38\n",
      "TRAINED AGENT\n",
      "Paso 41\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -40\n",
      "TRAINED AGENT\n",
      "Paso 42\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -42\n",
      "TRAINED AGENT\n",
      "Paso 43\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -44\n",
      "TRAINED AGENT\n",
      "Paso 44\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -46\n",
      "TRAINED AGENT\n",
      "Paso 45\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -48\n",
      "TRAINED AGENT\n",
      "Paso 46\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -50\n",
      "TRAINED AGENT\n",
      "Paso 47\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -52\n",
      "TRAINED AGENT\n",
      "Paso 48\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -54\n",
      "TRAINED AGENT\n",
      "Paso 49\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -56\n",
      "TRAINED AGENT\n",
      "Paso 50\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -58\n",
      "TRAINED AGENT\n",
      "Paso 51\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -60\n",
      "TRAINED AGENT\n",
      "Paso 52\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -62\n",
      "TRAINED AGENT\n",
      "Paso 53\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -64\n",
      "TRAINED AGENT\n",
      "Paso 54\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -66\n",
      "TRAINED AGENT\n",
      "Paso 55\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -68\n",
      "TRAINED AGENT\n",
      "Paso 56\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -70\n",
      "TRAINED AGENT\n",
      "Paso 57\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -72\n",
      "TRAINED AGENT\n",
      "Paso 58\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -74\n",
      "TRAINED AGENT\n",
      "Paso 59\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -76\n",
      "TRAINED AGENT\n",
      "Paso 60\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -78\n",
      "TRAINED AGENT\n",
      "Paso 61\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -80\n",
      "TRAINED AGENT\n",
      "Paso 62\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -82\n",
      "TRAINED AGENT\n",
      "Paso 63\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -84\n",
      "TRAINED AGENT\n",
      "Paso 64\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -86\n",
      "TRAINED AGENT\n",
      "Paso 65\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -88\n",
      "TRAINED AGENT\n",
      "Paso 66\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -90\n",
      "TRAINED AGENT\n",
      "Paso 67\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -92\n",
      "TRAINED AGENT\n",
      "Paso 68\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -94\n",
      "TRAINED AGENT\n",
      "Paso 69\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -96\n",
      "TRAINED AGENT\n",
      "Paso 70\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -98\n",
      "TRAINED AGENT\n",
      "Paso 71\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -100\n",
      "TRAINED AGENT\n",
      "Paso 72\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -102\n",
      "TRAINED AGENT\n",
      "Paso 73\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -104\n",
      "TRAINED AGENT\n",
      "Paso 74\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -106\n",
      "TRAINED AGENT\n",
      "Paso 75\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -108\n",
      "TRAINED AGENT\n",
      "Paso 76\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -110\n",
      "TRAINED AGENT\n",
      "Paso 77\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -112\n",
      "TRAINED AGENT\n",
      "Paso 78\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -114\n",
      "TRAINED AGENT\n",
      "Paso 79\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -116\n",
      "TRAINED AGENT\n",
      "Paso 80\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -118\n",
      "TRAINED AGENT\n",
      "Paso 81\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -120\n",
      "TRAINED AGENT\n",
      "Paso 82\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -122\n",
      "TRAINED AGENT\n",
      "Paso 83\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -124\n",
      "TRAINED AGENT\n",
      "Paso 84\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -126\n",
      "TRAINED AGENT\n",
      "Paso 85\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -128\n",
      "TRAINED AGENT\n",
      "Paso 86\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -130\n",
      "TRAINED AGENT\n",
      "Paso 87\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -132\n",
      "TRAINED AGENT\n",
      "Paso 88\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -134\n",
      "TRAINED AGENT\n",
      "Paso 89\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -136\n",
      "TRAINED AGENT\n",
      "Paso 90\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -138\n",
      "TRAINED AGENT\n",
      "Paso 91\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -140\n",
      "TRAINED AGENT\n",
      "Paso 92\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -142\n",
      "TRAINED AGENT\n",
      "Paso 93\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -144\n",
      "TRAINED AGENT\n",
      "Paso 94\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -146\n",
      "TRAINED AGENT\n",
      "Paso 95\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -148\n",
      "TRAINED AGENT\n",
      "Paso 96\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -150\n",
      "TRAINED AGENT\n",
      "Paso 97\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -152\n",
      "TRAINED AGENT\n",
      "Paso 98\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -154\n",
      "TRAINED AGENT\n",
      "Paso 99\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -156\n",
      "TRAINED AGENT\n",
      "Paso 100\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Accion 0 Estado 485 Recompensa -1 Total rec -158\n"
     ]
    }
   ],
   "source": [
    "rltaxi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ejercicio comparar recompensas de ambos metodos con 3 diferentes numeros de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
